{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ASTEncoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f777d2643afa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mASTEncoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mASTEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mCombinedRepresentation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCombinedRepresentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mDecoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ASTEncoder'"
     ]
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from ASTEncoder import ASTEncoder\n",
    "from CombinedRepresentation import CombinedRepresentation\n",
    "from Decoder import Decoder\n",
    "from Attention import Attention\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "def randContexts(batch_size, max_contexts, context_len):\n",
    "    return torch.tensor(\n",
    "        np.random.randint(0, 10, size=(batch_size, max_contexts, context_len))\n",
    "    )\n",
    "\n",
    "def randPaddedContexts(batch_size, max_contexts, context_len):\n",
    "    contexts = []\n",
    "    lengths = []\n",
    "    for i in range(0, batch_size * max_contexts):\n",
    "        rand_len = random.randint(1, context_len)\n",
    "        \n",
    "        lengths.append(rand_len)\n",
    "        context = np.random.randint(1, 10, size=(rand_len))\n",
    "        \n",
    "        padded_context = np.zeros(context_len)\n",
    "        padded_context[:context.shape[0]] = context\n",
    "        contexts.append(\n",
    "            padded_context\n",
    "        )\n",
    "#     torch.tensor(lengths).reshape(batch_size, max_contexts)\n",
    "    final_contexts = np.stack(contexts)\n",
    "    return torch.tensor(\n",
    "        final_contexts, dtype=torch.long\n",
    "    ).reshape(batch_size, max_contexts, context_len), lengths\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_contexts = 21\n",
    "batch_size = 5\n",
    "token_len = 6\n",
    "token_embedding_size = 7\n",
    "token_num_embeddings = 20\n",
    "ast_path_len = 10\n",
    "ast_num_embeddings = 30\n",
    "ast_embedding_size = 8\n",
    "ast_hidden_size = 30\n",
    "encoder_hidden = 27\n",
    "ast_bidirectional = True\n",
    "decoder_hidden = 27\n",
    "decoder_out = 31\n",
    "decoder_embedding_size = 7\n",
    "\n",
    "padded_encoder = CombinedRepresentation(\n",
    "     max_contexts,\n",
    "     token_len,\n",
    "     token_embedding_size,\n",
    "     token_num_embeddings,\n",
    "     ast_path_len,\n",
    "     ast_num_embeddings,\n",
    "     ast_embedding_size,\n",
    "     ast_hidden_size,\n",
    "     encoder_hidden,\n",
    "     ast_bidirectional=True,\n",
    "     ast_pad_idx=0\n",
    ")\n",
    "\n",
    "attention = Attention(\n",
    "    encoder_hidden,\n",
    "    decoder_hidden\n",
    ")\n",
    "\n",
    "decoder = Decoder(\n",
    "    decoder_out,\n",
    "    decoder_embedding_size,\n",
    "    encoder_hidden,\n",
    "    decoder_hidden,\n",
    "    0.5,\n",
    "    attention\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_contexts, path_lens = randPaddedContexts(batch_size, max_contexts, ast_path_len)\n",
    "start_contexts, _ = randPaddedContexts(batch_size, max_contexts, token_len)\n",
    "end_contexts, _ = randPaddedContexts(batch_size, max_contexts, token_len)\n",
    "decoder_previous = torch.tensor([2] * batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# embedding = nn.Embedding(ast_num_embeddings, ast_embedding_size, padding_idx=0)\n",
    "# padded_contexts\n",
    "# embedded = embedding(padded_contexts)\n",
    "# embedded = embedded.reshape(batch_size * max_contexts, ast_path_len, ast_embedding_size)\n",
    "\n",
    "# embedded_packed = torch.nn.utils.rnn.pack_padded_sequence(\n",
    "#                 embedded,\n",
    "#                 lengths,\n",
    "#                 batch_first=True,\n",
    "#                 enforce_sorted=False,\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(encoder, decoder, start, end, path, path_lens, decoder_h_prev):\n",
    "    encoded = encoder(start, end, path, path_lens)\n",
    "    decoder_initial = encoded.sum(dim=1) / max_contexts\n",
    "    decoder_initial.shape\n",
    "    pred, hidden = decoder(decoder_h_prev, decoder_initial, encoded)\n",
    "    \n",
    "    return pred, hidden\n",
    "\n",
    "# embedded_packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not padding\n"
     ]
    }
   ],
   "source": [
    "pred, _ = run(encoder, decoder, start_contexts, end_contexts, path_contexts, path_lens, decoder_previous)\n",
    "pred_packed, _ = run(padded_encoder, decoder, start_contexts, end_contexts, path_contexts, path_lens, decoder_previous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input = [batch size] the previous prediction or ground truth if using teacher forcing\n",
    "# hidden = [batch size, dec hid dim]\n",
    "# encoder_outputs = [src len, batch size, enc hid dim * 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0192,  0.2672,  0.3908,  0.1093,  0.2075, -0.4593, -0.1799, -0.9357,\n",
       "         -0.7444, -0.0676,  0.1363,  0.3206, -0.8241, -0.1877, -0.2045, -0.4505,\n",
       "         -0.2019, -0.6395,  0.5510, -0.0419, -0.6607,  0.0188,  0.3983,  0.6107,\n",
       "          0.3753,  0.5021, -0.4667, -0.4846,  0.7062, -0.0253, -0.1780],\n",
       "        [ 0.0953, -0.0882,  0.3342, -0.3160,  0.5703, -0.1083, -0.1204, -0.7152,\n",
       "         -0.2773, -0.2063,  0.1920, -0.0682, -0.4073, -0.3183,  0.1385, -0.1170,\n",
       "          0.2447, -0.0655,  0.2473, -0.0940, -0.3435, -0.0669, -0.0949,  0.5371,\n",
       "          0.3143,  0.2550, -0.0815, -0.3280,  0.3665, -0.3363,  0.1134],\n",
       "        [ 0.2581,  0.1374,  0.5975,  0.5561,  0.1268, -1.1876,  0.3828, -0.4699,\n",
       "         -0.3717,  0.2166,  0.6081,  0.0838, -0.3799, -0.6094, -0.5966, -0.6883,\n",
       "          0.1776, -0.9161, -0.2207,  0.4199, -0.2658, -0.1434,  0.1715,  1.1473,\n",
       "         -0.0260,  0.7278,  0.4953, -0.7427,  0.5782,  0.2400, -0.4009],\n",
       "        [ 0.3627, -0.0037,  0.4645,  0.6881,  0.2761, -1.3234,  0.2846, -0.2868,\n",
       "         -0.2490,  0.0504,  1.0725,  0.1657, -0.2130, -0.2265, -0.1345, -0.8009,\n",
       "          0.3884, -0.6943, -0.0838,  0.6365, -0.3730,  0.1073,  0.2716,  0.8697,\n",
       "         -0.3048,  1.0366,  0.2430, -0.7597,  0.7874,  0.3216, -0.2423],\n",
       "        [ 0.3683, -0.0473,  0.7723,  0.4233,  0.4040, -0.6137,  0.3665,  0.1387,\n",
       "          0.2752, -0.2041,  0.8582, -0.2567,  0.4452, -0.1979,  0.0524, -0.7119,\n",
       "          0.7235,  0.0779, -0.2781,  0.8881,  0.2246, -0.2417, -0.0418,  0.3111,\n",
       "         -0.3802,  0.9034,  0.5262, -0.3186,  0.0572,  0.0807,  0.0036]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5193,  0.2451,  0.7190,  0.7391, -0.3771, -0.6199,  0.4121,  0.4511,\n",
       "         -0.1682,  0.5793,  0.2046,  0.0249, -0.4175, -0.3419, -0.7307, -0.5142,\n",
       "         -0.4812, -0.9429,  0.1567,  0.3886, -0.0259, -0.2589, -0.1656,  0.6226,\n",
       "          0.0855,  0.2261,  0.2862, -0.2775,  0.2412,  0.5069, -0.0487],\n",
       "        [ 0.3137, -0.1608,  0.2010,  0.7114, -0.0136, -1.0614, -0.3065,  0.0367,\n",
       "         -0.2455,  0.2886,  0.4840,  0.9368, -0.6769,  0.2800,  0.1564, -0.4040,\n",
       "         -0.4028, -0.7503,  0.2990, -0.2819, -0.9769,  0.6266,  0.0493,  0.1531,\n",
       "         -0.0408,  0.0636, -0.5215, -0.2778,  0.5189,  0.2338,  0.1777],\n",
       "        [ 0.5766,  0.0121,  0.6500,  0.2346, -0.0564, -0.2214,  0.4508,  0.6085,\n",
       "          0.2080,  0.4678,  0.2434, -0.3284, -0.1483, -0.3799, -0.4861, -0.2664,\n",
       "          0.0030, -0.3168, -0.2338,  0.2431,  0.0899, -0.4979, -0.6430,  0.4714,\n",
       "          0.0061,  0.0960,  0.6067, -0.1599, -0.1262,  0.1542,  0.3333],\n",
       "        [ 0.1029,  0.0600,  0.4567,  0.7435, -0.2666, -0.6215, -0.1655,  0.2777,\n",
       "         -0.2957,  0.2499,  0.2280,  0.6535, -0.3625,  0.4575,  0.1898, -0.4282,\n",
       "         -0.4079, -0.3563,  0.5453,  0.1410, -0.7422,  0.5254,  0.0332, -0.0605,\n",
       "          0.0715,  0.2167, -0.5198, -0.0983,  0.2273,  0.5733,  0.1822],\n",
       "        [ 0.6747,  0.1502,  0.6157,  0.6217, -0.1728, -0.9706,  0.3171,  0.1540,\n",
       "         -0.4421,  0.8067,  0.5126,  0.1731, -0.6538, -0.4571, -0.5397, -0.2430,\n",
       "         -0.4280, -1.1970, -0.1729, -0.0304, -0.5754, -0.0820, -0.3250,  0.9923,\n",
       "          0.0375,  0.2253,  0.3601, -0.5348,  0.6015,  0.3848,  0.0998]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-e8d7a83487f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpath_contexts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "path_contexts.index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FileReader import FileReader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FileReader:\n",
    "    def __init__(self, filename):\n",
    "        if not os.path.exists(filename) and os.path.isfile(filename):\n",
    "            raise Exception(\"Not a valid filename\")\n",
    "\n",
    "        self.file = open(filename, \"r\")\n",
    "        self.line_offsets = {}\n",
    "\n",
    "        offset = 0\n",
    "        line = self.file.readline()\n",
    "        line_number = 0\n",
    "\n",
    "        while line:\n",
    "            self.line_offsets[line_number] = offset\n",
    "            offset = offset + len(line)\n",
    "            line = self.file.readline()\n",
    "            line_number += 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, slice):\n",
    "            idx = list(range(idx.start or 0, idx.stop or len(self), idx.step or 1))\n",
    "            return [self[i] for i in idx]\n",
    "        else:\n",
    "            self.file.seek(0)\n",
    "            self.file.seek(self.line_offsets[idx])\n",
    "\n",
    "            return self.file.readline().rstrip()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.line_offsets)\n",
    "\n",
    "    def __del__(self):\n",
    "        self.file.close()\n",
    "\n",
    "data_root = \"./data/java-small/\"\n",
    "train_file_path = os.path.join(data_root, \"java-small.train.c2s\")\n",
    "test_file_path = os.path.join(data_root, \"java-small.test.c2s\")\n",
    "dict_file_path = os.path.join(data_root, \"java-small.dict.c2s\")\n",
    "        \n",
    "\n",
    "f = FileReader(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['get|timestamp override,Nm0|MarkerExpr|Mth|Prim1,long override,Nm0|MarkerExpr|Mth|Nm2,METHOD_NAME long,Prim1|Mth|Nm2,METHOD_NAME long,Prim1|Mth|Bk|Ret|Nm0,timestamp METHOD_NAME,Nm2|Mth|Bk|Ret|Nm0,timestamp',\n",
       " 'get|type override,Nm0|MarkerExpr|Mth|Cls1,type override,Nm0|MarkerExpr|Mth|Nm2,METHOD_NAME type,Cls1|Mth|Nm2,METHOD_NAME type,Cls1|Mth|Bk|Ret|Nm0,type METHOD_NAME,Nm2|Mth|Bk|Ret|Nm0,type']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57088"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(4* 3, 2).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (x == 0.3357)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_mask(lengths, maxlen=None, dtype=torch.bool):\n",
    "    if maxlen is None:\n",
    "        maxlen = lengths.max()\n",
    "    row_vector = torch.arange(0, maxlen, 1)\n",
    "    matrix = torch.unsqueeze(lengths, dim=-1)\n",
    "    mask = row_vector < matrix\n",
    "\n",
    "    mask.type(dtype)\n",
    "    return mask\n",
    "\n",
    "sample = randPaddedContexts(4, 3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.tensor([\n",
    "    [4, 5, 6, 0],\n",
    "    [2, 3, 0 ,0]\n",
    "])\n",
    "\n",
    "lengths = [3, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = sequence_mask(torch.tensor(lengths), maxlen=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6, 2, 3])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[masks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(3, 4, 5)\n",
    "b = torch.rand(3, 4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2331, 0.8801, 0.5692, 0.5974, 0.3704],\n",
       "         [0.3491, 0.0106, 0.4078, 0.8475, 0.1214],\n",
       "         [0.8971, 0.6593, 0.7773, 0.2005, 0.3652],\n",
       "         [0.4523, 0.2859, 0.1618, 0.0165, 0.1110]],\n",
       "\n",
       "        [[0.6816, 0.0917, 0.1544, 0.4621, 0.0504],\n",
       "         [0.9050, 0.5085, 0.0426, 0.5298, 0.7987],\n",
       "         [0.9161, 0.1003, 0.8156, 0.9963, 0.2665],\n",
       "         [0.2426, 0.1371, 0.8620, 0.8919, 0.2236]],\n",
       "\n",
       "        [[0.6881, 0.7284, 0.4124, 0.9517, 0.3423],\n",
       "         [0.4180, 0.1295, 0.4357, 0.0583, 0.8912],\n",
       "         [0.0814, 0.3708, 0.3269, 0.3841, 0.6103],\n",
       "         [0.7462, 0.5383, 0.8795, 0.3500, 0.2957]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2361, 0.0671, 0.8564, 0.2366, 0.7370],\n",
       "         [0.4328, 0.3619, 0.6318, 0.0997, 0.8898],\n",
       "         [0.2398, 0.0861, 0.4448, 0.2729, 0.6475],\n",
       "         [0.4641, 0.4559, 0.9215, 0.8726, 0.8068]],\n",
       "\n",
       "        [[0.5168, 0.6759, 0.1737, 0.8454, 0.1579],\n",
       "         [0.1556, 0.8148, 0.3759, 0.7560, 0.6981],\n",
       "         [0.0793, 0.1141, 0.5935, 0.8008, 0.9047],\n",
       "         [0.0982, 0.9480, 0.2922, 0.6172, 0.5895]],\n",
       "\n",
       "        [[0.1245, 0.9845, 0.8202, 0.4375, 0.3517],\n",
       "         [0.6666, 0.7005, 0.7619, 0.7581, 0.4217],\n",
       "         [0.7488, 0.6469, 0.4195, 0.6232, 0.7563],\n",
       "         [0.3748, 0.6338, 0.8799, 0.7805, 0.8928]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((a, b), dim=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sum(dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_counts(filename):\n",
    "    freqs = {}\n",
    "    i = 0\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            token, count = line.split(\"|\")\n",
    "            freqs[token] = int(count)\n",
    "            i += 1\n",
    "    return freqs\n",
    "    \n",
    "# os.listdir(\"./data/java-test\")[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_count = load_counts(\"./data/java-test/target_count.txt\")\n",
    "node_count = load_counts(\"./data/java-test/node_count.txt\")\n",
    "subtoken_count = load_counts(\"./data/java-test/subtoken_count.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_by_quantile(kv, threshold=0.25):\n",
    "    q = np.quantile(np.array(list(kv.values())), 0.25)\n",
    "    return {k:v for k,v in kv.items() if v > q}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'q' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-d7c5e77f0cd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtarget_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrim_by_quantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnode_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrim_by_quantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msubtoken_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrim_by_quantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubtoken_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-3f9849609ca1>\u001b[0m in \u001b[0;36mtrim_by_quantile\u001b[0;34m(kv, threshold)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrim_by_quantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'q' referenced before assignment"
     ]
    }
   ],
   "source": [
    "target_count = trim_by_quantile(target_count)\n",
    "node_count = trim_by_quantile(node_count)\n",
    "subtoken_count = trim_by_quantile(subtoken_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(node_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./data/java-test/java-test.dict.c2s\", 'wb') as file:\n",
    "    pickle.dump(subtoken_count, file)\n",
    "    pickle.dump(node_count, file)\n",
    "    pickle.dump(target_count, file)\n",
    "    pickle.dump(200, file)\n",
    "    pickle.dump(57000, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_subtoken = [{\"token\": k, \"freq\": v} for k, v in sorted(subtoken_count.items(), key=lambda item: item[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sorted_subtoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.freq.quantile(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111656"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.freq > 13].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153022"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
